# **S3 Baseline Performance.**

* Amazon S3 automatically scales to high request rates & latency (100-200 ms).
* Applications can achieve at least 3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second per prefix per bucket.
* There are no limits to the number of prefixes in your buckets.
* If you spread reads across all four prefixes evenly, you can achieve 22000 requests per second for GET & HEAD.

##  **KMS Limitation.**

* If you use SSE-KMS to encrypt your objects, you may be impacted by KMS limits.
* When you upload a file, the application will call the GenerateDataKey KMS API.
* When you download a file, the application will call the Decrypt KMS API.
* These will count towards the KMS quota per second.
* You can request a quota increase using the Service Quotas Console.


## **S3 Performance.**

* **Multi-Part Upload:**
    * It is recommended for files that are over 100MB.
    * Can help parallelize uploads (speeds up transfers).
    * Splits up files & uploads them simultaneously into one final file.
* **S3 Transfer Acceleration:**
    * Increase transfer speed by transferring files to an AWS edge location which will forward the data to the S3 bucket in the target region.
    * Compatible with multi-part upload.

## **S3 Byte-Range Fetches.**

* Parallelize GET requests by requesting specific byte ranges.
* Better resilience in case of failures.
* Works by specifying byte ranges to retrieve - i.e. if we want to download a 100MB file we might download the file in 2 MB chunks in parallel.
* This can speed up downloads.
* Can also be used to retrieve only a partial amount of data - this is called a HEAD request.